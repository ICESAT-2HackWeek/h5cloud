{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9b37e2-2daa-4283-a228-ea581498de0c",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## AB testing access time for ICESat-2 HDF5 files on the cloud.\n",
    "\n",
    "This notebook requires that we have 2 versions of the same file:\n",
    "  * Original A: The original file with no modifications on a S3 location.\n",
    "  * Test Case B: A modified version of the orignal file to test for metadata consolidation, rechunking and other strategies to speed up access to the data in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b78fb94-10ae-48cb-8e30-521b2c8b7822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray v2023.12.0\n",
      "h5py v3.10.0\n",
      "fsspec v2023.6.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import h5py\n",
    "import fsspec\n",
    "import s3fs\n",
    "import boto3\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class RegexFilter(logging.Filter):\n",
    "    def __init__(self, regex_pattern):\n",
    "        super(RegexFilter, self).__init__()\n",
    "        self.regex_pattern = re.compile(regex_pattern)\n",
    "\n",
    "    def filter(self, record):\n",
    "        # Apply the regex pattern to the log message\n",
    "        return not bool(self.regex_pattern.search(record.msg))\n",
    "\n",
    "    \n",
    "def timer_decorator(func):\n",
    "    \"\"\"\n",
    "    A decorator to measure the execution time of the wrapped function.\n",
    "    \"\"\"\n",
    "    def __setup_logging(self, tstamp):\n",
    "        log_filename = f\"logs/{self.data_format}-{tstamp}.log\"\n",
    "        logger = logging.getLogger(\"fsspec\")\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        self.regex_filter = RegexFilter(self.logs_regex)\n",
    "        # add regerx to root logger\n",
    "        logging.getLogger().addFilter(self.regex_filter )\n",
    "        self._file_handler = logging.FileHandler(log_filename)\n",
    "        self._file_handler.setLevel(logging.DEBUG)\n",
    "        # Add the handler to the root logger\n",
    "        logging.getLogger().addHandler(self._file_handler)\n",
    "        \n",
    "    def __turnoff_logging(self):\n",
    "        logging.getLogger().removeFilter(self.regex_filter)\n",
    "        logging.getLogger().removeHandler(self._file_handler)\n",
    "        self._file_handler.close()\n",
    "        \n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        tstamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "        if self.logs_regex:\n",
    "            __setup_logging(self, tstamp)\n",
    "        start_time = time.time()\n",
    "        result = func(self, *args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        if self.logs_regex:\n",
    "            __turnoff_logging(self)\n",
    "        execution_time = end_time - start_time\n",
    "        # Call the store method here\n",
    "        if self.store_results:\n",
    "            results_key = f\"{tstamp}_{self.name}_{self.data_format}_results.csv\"\n",
    "            s3_key = f\"{self.results_directory}/{results_key}\"\n",
    "            self.store(run_time=execution_time, result=result, bucket=self.bucket, s3_key=s3_key)\n",
    "        return result, execution_time\n",
    "    return wrapper  \n",
    "\n",
    "\n",
    "    \n",
    "class H5Test:\n",
    "    def __init__(self,\n",
    "                 data_format: str,\n",
    "                 files=None,\n",
    "                 store_results=True,\n",
    "                 logs_regex=None):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.data_format = data_format\n",
    "        self.logs_regex = logs_regex\n",
    "        if files:\n",
    "            self.files = files\n",
    "        else:\n",
    "            self.files = S3Links().get_links_by_format(data_format)\n",
    "        self.s3_client = boto3.client('s3')  # Ensure AWS credentials are configured\n",
    "        self.s3_fs = s3fs.S3FileSystem(anon=False)\n",
    "        self.store_results = store_results\n",
    "        self.bucket = \"nasa-cryo-persistent\"\n",
    "        self.results_directory = \"h5cloud/benchmark_results\"\n",
    "        \n",
    "      \n",
    "\n",
    "    @timer_decorator\n",
    "    def run(self, io_params):\n",
    "        raise NotImplementedError(\"The run method has not been implemented\")\n",
    "\n",
    "    def store(self, run_time: float, result: str, bucket: str, s3_key: str):\n",
    "        \"\"\"\n",
    "        Store test results to an S3 bucket as a CSV file.\n",
    "\n",
    "        :param run_time: The runtime of the test\n",
    "        :param result: The result of the test\n",
    "        :param bucket: The name of the S3 bucket where the CSV will be uploaded\n",
    "        :param s3_key: The S3 key (filename) where the CSV will be stored\n",
    "        \"\"\"\n",
    "        # Create a CSV in-memory\n",
    "        csv_buffer = StringIO()\n",
    "        csv_writer = csv.writer(csv_buffer)\n",
    "        csv_writer.writerow(['Name', 'Data Format', 'Run Time', 'Result'])  # Headers\n",
    "        csv_writer.writerow([self.name, self.data_format, run_time, result])\n",
    "\n",
    "        # Reset the buffer's position to the beginning\n",
    "        csv_buffer.seek(0)\n",
    "\n",
    "        # Upload the CSV to S3\n",
    "        self.s3_client.put_object(Bucket=bucket, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "for library in (xr, h5py, fsspec):\n",
    "    print(f'{library.__name__} v{library.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ed86c7-a919-4532-b7d3-1ca3cf4e25d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class H5pyArrMean(H5Test):\n",
    "    \n",
    "    @timer_decorator\n",
    "    def run(self, io_params):\n",
    "        final_h5py_array = []  \n",
    "        # TODO: Do we need to make this configurable or consistent?\n",
    "        group = '/gt1l/heights'\n",
    "        variable = 'h_ph'\n",
    "        fsspec_params = io_params[\"fsspec_params\"]\n",
    "        h5py_params = io_params[\"h5py_params\"]\n",
    "        for file in self.files:\n",
    "            with self.s3_fs.open(file, mode=\"rb\", **fsspec_params) as fo:\n",
    "                with h5py.File(fo, **h5py_params) as f:\n",
    "                    data = f[f\"{group}/{variable}\"][:]\n",
    "                    final_h5py_array = np.insert(\n",
    "                        final_h5py_array,\n",
    "                        len(final_h5py_array),\n",
    "                        data, axis=None\n",
    "                    )\n",
    "        return np.mean(final_h5py_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7c600-d362-45c2-bb9f-3670de9ddf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5pyROS3ArrMean(H5Test):\n",
    "    \"\"\"\n",
    "        This will only work for public buckets for now\n",
    "    \"\"\"\n",
    "    \n",
    "    @timer_decorator\n",
    "    def run(self, io_params):\n",
    "        final_h5py_array = []  \n",
    "        # TODO: Do we need to make this configurable or consistent?\n",
    "        group = '/gt1l/heights'\n",
    "        variable = 'h_ph'\n",
    "        h5py_params = io_params[\"h5py_params\"]\n",
    "        for file in self.files:\n",
    "            with h5py.File(file, driver=\"ros3\", **h5py_params) as f:\n",
    "                data = f[f\"{group}/{variable}\"][:]\n",
    "                final_h5py_array = np.insert(\n",
    "                    final_h5py_array,\n",
    "                    len(final_h5py_array),\n",
    "                    data, axis=None\n",
    "                )\n",
    "        return np.mean(final_h5py_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621f6014-fda5-40a4-be23-dcaed47b6fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XarrayArrMean(H5Test):\n",
    "    def open_reference_ds(self, file):\n",
    "        fs = fsspec.filesystem(\n",
    "            'reference', \n",
    "            fo=file, \n",
    "            remote_protocol='s3', \n",
    "            remote_options=dict(anon=False), \n",
    "            skip_instance_cache=True\n",
    "        )\n",
    "        return xr.open_dataset(fs.get_mapper(\"\"), engine='zarr', consolidated=False, group='gt1l/heights')\n",
    "\n",
    "    @timer_decorator\n",
    "    def run(self, io_params):\n",
    "        group = '/gt1l/heights'\n",
    "        variable = 'h_ph'\n",
    "\n",
    "        if 'kerchunk' in self.data_format:            \n",
    "            datasets = [self.open_reference_ds(file) for file in self.files]\n",
    "            h_ph_values = []\n",
    "            for dataset in datasets:\n",
    "                h_ph_values = np.append(h_ph_values, dataset['h_ph'].values)\n",
    "            return np.mean(h_ph_values)\n",
    "        else:\n",
    "            if \"repacked\" in self.data_format:\n",
    "                fsspec_params = {\n",
    "                    # \"skip_instance_cache\": True\n",
    "                    \"cache_type\": \"first\",\n",
    "                    \"block_size\": 16*1024*1024\n",
    "                }\n",
    "                h5py_params = {\n",
    "                    \"driver_kwds\" :{\n",
    "                        \"page_buf_size\": 32*1024*1024,\n",
    "                        \"rdcc_nbytes\": 8*1024*1024\n",
    "                    }\n",
    "                }            \n",
    "            s3_fileset = [self.s3_fs.open(file, **fsspec_params) for file in self.files]\n",
    "            xrds = xr.open_mfdataset(s3_fileset, group=group, combine='by_coords', engine='h5netcdf', **h5py_params)\n",
    "            h_ph_values = xrds['h_ph']\n",
    "            return float(np.mean(h_ph_values).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6d4b6ce-10f1-4031-987d-fcfd43422ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repacked_granules = [\n",
    "    \"s3://nasa-cryo-persistent/h5cloud/atl03/big/repacked/ATL03_20181120182818_08110112_006_02_repacked.h5\",\n",
    "    \"s3://nasa-cryo-persistent/h5cloud/atl03/big/repacked/ATL03_20190219140808_08110212_006_02_repacked.h5\",\n",
    "]\n",
    "test_cloud = H5pyArrMean('atl03-bigsize-repacked',\n",
    "                         files=repacked_granules,\n",
    "                         store_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dfe5ab6-2e88-46d3-bb19-d6ebcec2d341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "original_granules = [\n",
    "    \"s3://nasa-cryo-persistent/h5cloud/atl03/big/original/ATL03_20181120182818_08110112_006_02.h5\",\n",
    "    \"s3://nasa-cryo-persistent/h5cloud/atl03/big/original/ATL03_20190219140808_08110212_006_02.h5\",\n",
    "]\n",
    "\n",
    "logs_regex = r\"<File-like object S3FileSystem, .*?>\\s*(read: \\d+ - \\d+)\"\n",
    "\n",
    "test_original = H5pyArrMean('atl03-bigsize-original',\n",
    "                            files=original_granules,\n",
    "                            store_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ef2c85-f4d2-4a03-9839-bc192dda0c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032.9840463639412, 12.149354219436646)\n",
      "(1032.9840463639412, 12.194729566574097)\n",
      "(1032.9840463639412, 12.10885739326477)\n",
      "(1032.9840463639412, 11.940461874008179)\n",
      "(1032.9840463639412, 12.063915252685547)\n"
     ]
    }
   ],
   "source": [
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "io_params ={\n",
    "    \"fsspec_params\": {\n",
    "        \"skip_instance_cache\": True\n",
    "        # \"cache_type\": \"blockcache\",\n",
    "        # \"block_size\": 4*1024*1024\n",
    "    },\n",
    "    \"h5py_params\": {\n",
    "        # \"rdcc_nbytes\": 2*1024*1024        \n",
    "    }\n",
    "}\n",
    "for runs in range(5):\n",
    "    print(test_original.run(io_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f92bf-4b1f-4bfe-a037-8061bfa9b127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032.9840463639412, 34.1772985458374)\n",
      "(1032.9840463639412, 30.96499228477478)\n",
      "(1032.9840463639412, 31.00865602493286)\n",
      "(1032.9840463639412, 31.207276821136475)\n"
     ]
    }
   ],
   "source": [
    "io_params ={\n",
    "    \"fsspec_params\": {\n",
    "        # \"skip_instance_cache\": True\n",
    "        # \"cache_type\": \"blockcache\",\n",
    "        # \"block_size\": 4*1024*1024\n",
    "    },\n",
    "    \"h5py_params\": {\n",
    "        # \"page_buf_size\": 32*1024*1024,\n",
    "        # \"rdcc_nbytes\": 2*1024*1024\n",
    "    }\n",
    "}\n",
    "for runs in range(5):\n",
    "    print(test_cloud.run(io_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "262a6b25-8b23-46bb-8301-8965aaf155d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered drivers: frozenset({'mpio', 'family', 'ros3', 'split', 'core', 'sec2', 'fileobj', 'direct', 'stdio'})\n"
     ]
    }
   ],
   "source": [
    "print(f'Registered drivers: {h5py.registered_drivers()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02258a85-4951-48c2-a295-75a47c0e38c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame.from_dict(benchmarks)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for name, group in df.groupby(['tool', 'dataset', 'format']):\n",
    "    tool, dataset, formated = name\n",
    "    x = f'{tool}, {dataset}, {formated}'\n",
    "    y = group['time'].mean()\n",
    "    ax.bar(f'{tool}, {dataset}, {formated}', group['time'].mean(), label=f'{tool}, {dataset}, {formated}', align='center')\n",
    "    ax.text(x, y + 0.05, f'{group[\"time\"].mean():.2f}', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Combination')\n",
    "ax.set_ylabel('Time in Seconds')\n",
    "ax.set_title('mean() on photon data for a single IS2 track, less is better')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# # Show legend\n",
    "# ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "with plt.xkcd():\n",
    "    # This figure will be in XKCD-style\n",
    "    fig1 = plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d779b-5bc6-4208-ae26-05c5a473d9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcc5de-aae3-46aa-9474-1c90b9ff20a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame.from_dict(benchmarks)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for name, group in df.groupby(['tool', 'dataset', 'format']):\n",
    "    tool, dataset, formated = name\n",
    "    x = f'{tool}, {dataset}, {formated}'\n",
    "    y = group['time'].mean()\n",
    "    ax.bar(f'{tool}, {dataset}, {formated}', group['time'].mean(), label=f'{tool}, {dataset}, {formated}', align='center')\n",
    "    ax.text(x, y + 0.05, f'{group[\"time\"].mean():.2f}', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Combination')\n",
    "ax.set_ylabel('Time in Seconds')\n",
    "ax.set_title('mean() on photon data for a single IS2 track, less is better')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# # Show legend\n",
    "# ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2871e1-d700-4d22-b01f-5e5a9acd1006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aabece-d942-418c-b387-77ea2de1e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_log(log_file):\n",
    "#     with open(log_file, 'r') as input_file:\n",
    "#     # Open the output file in write mode\n",
    "#         with open(f'{log_file.replace(\".log\", \"-ros-compatible.log\")}', 'w') as output_file:\n",
    "#             # Iterate through each line in the input file\n",
    "#             for line in input_file:\n",
    "#                 # Strip leading and trailing whitespaces from the line\n",
    "#                 stripped_line = line.strip()\n",
    "\n",
    "#                 # Write the stripped line to the output file\n",
    "#                 output_file.write(stripped_line + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411f4a8-22b4-424e-b817-0d31e7ac9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # \"ATL08\": {\n",
    "    #     \"links\": {\n",
    "    #         \"original\": \"s3://nasa-cryo-persistent/h5cloud/atl08/original/ATL08_20200404075919_01340707_006_03.h5\",\n",
    "    #         \"optimized\": \"s3://nasa-cryo-persistent/h5cloud/atl08/repacked/ATL08_20200404075919_01340707_006_03_repacked.h5\",\n",
    "    #     },\n",
    "    #     \"group\": \"/gt1l/signal_photons\",\n",
    "    #     \"variable\": \"ph_h\",\n",
    "    #     \"processing\": [\n",
    "    #         \"h5repack -S PAGE -G 4000000\"\n",
    "    #     ]\n",
    "    # },\n",
    "    # \"ATL03\": {\n",
    "    #     \"links\": {\n",
    "    #         \"original\": \"s3://nasa-cryo-persistent/h5cloud/atl03/average/original/ATL03_20230618223036_13681901_006_01.h5\",\n",
    "    #         \"optimized\": \"s3://nasa-cryo-persistent/h5cloud/atl03/average/repacked/ATL03_20230618223036_13681901_006_01.h5\"\n",
    "    #     },\n",
    "    #     \"group\": \"/gt1l/heights\",\n",
    "    #     \"variable\": \"h_ph\",\n",
    "    #     \"processing\": [\n",
    "    #         \"h5repack -S PAGE -G 4000000\"\n",
    "    #     ]\n",
    "    # },"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
