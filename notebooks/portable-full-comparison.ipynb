{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9b37e2-2daa-4283-a228-ea581498de0c",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## AB testing access time for ICESat-2 ATL03 HDF5 files in the cloud.\n",
    "\n",
    "This notebook requires that we have 2 versions of the same file:\n",
    "  * Original A: The original file with no modifications on a S3 location.\n",
    "  * Test Case B: A modified version of the orignal file to test for metadata consolidation, rechunking and other strategies to speed up access to the data in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca84b1-46e9-4b41-a494-24da3a368f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mamba uninstall -y h5coro \n",
    "%pip install git+https://github.com/ICESat2-SlideRule/h5coro.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78fb94-10ae-48cb-8e30-521b2c8b7822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import h5py\n",
    "import fsspec\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from h5coro import h5coro, s3driver, filedriver\n",
    "driver =  s3driver.S3Driver\n",
    "\n",
    "logger = logging.getLogger('fsspec')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d900d-0656-4b75-af6b-82f0f171d5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for library in (xr, h5py, fsspec, h5coro):\n",
    "    print(f'{library.__name__} v{library.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998cd99-6034-4a1b-9ae5-d651bc265bff",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "For listing files in CryoCloud\n",
    "\n",
    "```bash\n",
    "aws s3 ls s3://nasa-cryo-persistent/h5cloud/ --recursive\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850faac-f534-4bc2-9214-c8dababe0f52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    \"ATL03-1GB\": {\n",
    "        \"links\": {\n",
    "            \"original\": \"s3://nasa-cryo-persistent/h5cloud/atl03/average/original/ATL03_20230618223036_13681901_006_01.h5\",\n",
    "            \"optimized\": \"s3://nasa-cryo-persistent/h5cloud/atl03/average/repacked/ATL03_20230618223036_13681901_006_01.h5\"\n",
    "        },\n",
    "        \"group\": \"/gt1l/heights\",\n",
    "        \"variable\": \"h_ph\",\n",
    "        \"processing\": [\n",
    "            \"h5repack -S PAGE -G 8000000\"\n",
    "        ]\n",
    "    },\n",
    "    \"ATL03-7GB\": {\n",
    "        \"links\": {\n",
    "            \"original\": \"s3://nasa-cryo-persistent/h5cloud/atl03/big/original/ATL03_20181120182818_08110112_006_02.h5\",\n",
    "            \"optimized\": \"s3://nasa-cryo-persistent/h5cloud/atl03/big/repacked/ATL03_20181120182818_08110112_006_02_repacked.h5\",\n",
    "        },\n",
    "        \"group\": \"/gt1l/heights\",\n",
    "        \"variable\": \"h_ph\",\n",
    "        \"processing\": [\n",
    "            \"h5repack -S PAGE -G 8000000\"\n",
    "        ]\n",
    "    },\n",
    "    \"ATL03-7GB-kerchunk\": {\n",
    "        \"links\": {\n",
    "            \"original\": \"s3://nasa-cryo-persistent/h5cloud/atl03/big/original/kerchunk/atl03_ATL03_20181120182818_08110112_006_02.json\",\n",
    "            \"optimized\": \"s3://nasa-cryo-persistent/h5cloud/atl03/big/repacked/kerchunk/atl03_ATL03_20181120182818_08110112_006_02_repacked.json\",\n",
    "        },\n",
    "        \"group\": \"/gt1l/heights\",\n",
    "        \"variable\": \"h_ph\",\n",
    "        \"processing\": [\n",
    "            \"h5repack -S PAGE -G 8000000\"\n",
    "        ]\n",
    "    },    \n",
    "    \"ATL03-2GB\": {\n",
    "        \"links\": {\n",
    "            \"original\": \"s3://nasa-cryo-persistent/h5cloud/atl03/big/original/ATL03_20210402143840_01341107_006_02.h5\",\n",
    "            \"optimized\": \"s3://nasa-cryo-persistent/h5cloud/atl03/big/repacked/ATL03_20210402143840_01341107_006_02_repacked.h5\",\n",
    "        },\n",
    "        \"group\": \"/gt1l/heights\",\n",
    "        \"variable\": \"h_ph\",\n",
    "        \"processing\": [\n",
    "            \"h5repack -S PAGE -G 8000000\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def kerchunk_result(file: str, dataset: str, variable: str):\n",
    "    fs = fsspec.filesystem(\n",
    "        \"reference\",\n",
    "        fo=file,\n",
    "        remote_protocol=\"s3\",\n",
    "        remote_options=dict(anon=False),\n",
    "        skip_instance_cache=True,\n",
    "    )\n",
    "    ds = xr.open_dataset(\n",
    "        fs.get_mapper(\"\"), engine=\"zarr\", consolidated=False, group=dataset\n",
    "    )\n",
    "    return ds[variable].mean()\n",
    "\n",
    "# This will use the embedded credentials in the hub to access the s3://nasa-cryo-persistent bucket\n",
    "fs = fsspec.filesystem('s3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d166627-6144-40bf-884d-2188e5c764ba",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## [h5coro](https://github.com/ICESat2-SlideRule/h5coro/)\n",
    "\n",
    "**h5coro** is optimized for reading HDF5 data in high-latency high-throughput environments.  It accomplishes this through a few key design decisions:\n",
    "* __All reads are concurrent.__  Each dataset and/or attribute read by **h5coro** is performed in its own thread.\n",
    "* __Intelligent range gets__ are used to read as many dataset chunks as possible in each read operation.  This drastically reduces the number of HTTP requests to S3 and means there is no longer a need to re-chunk the data (it actually works better on smaller chunk sizes due to the granularity of the request).\n",
    "* __Block caching__ is used to minimize the number of GET requests made to S3.  S3 has a large first-byte latency (we've measured it at ~60ms on our systems), which means there is a large penalty for each read operation performed.  **h5coro** performs all reads to S3 as large block reads and then maintains data in a local cache for access to smaller amounts of data within those blocks.\n",
    "* __The system is serverless__ and does not depend on any external services to read the data. This means it scales naturally as the user application scales, and it reduces overall system complexity.\n",
    "* __No metadata repository is needed.__  The structure of the file are cached as they are read so that successive reads to other datasets in the same file will not have to re-read and re-build the directory structure of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe41d4a-1947-438b-a3c3-7ab954d75e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5coro_beanchmarks = []\n",
    "\n",
    "for key, dataset in test_dict.items():\n",
    "    for k, link in dataset[\"links\"].items():\n",
    "        print (f\"Processing: {link}\")\n",
    "        if \"kerchunk\" in link:\n",
    "            continue\n",
    "        group = dataset[\"group\"]\n",
    "        variable = dataset['variable']     \n",
    "        final_h5coro_array = []\n",
    "        start = time.time()\n",
    "        if link.startswith(\"s3://nasa-cryo-persistent/\"):\n",
    "            h5obj = h5coro.H5Coro(link.replace(\"s3://\", \"\"), s3driver.S3Driver)\n",
    "        else:\n",
    "            h5obj = h5coro.H5Coro(link.replace(\"s3://\", \"\"), s3driver.S3Driver, credentials={\"annon\": True})\n",
    "        ds = h5obj.readDatasets(datasets=[f'{group}/{variable}'], block=True)\n",
    "        data = ds[f'{group}/{variable}'][:]\n",
    "        data_mean = np.mean(data)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        h5coro_beanchmarks.append({\"tool\": \"h5coro\",\n",
    "                                   \"dataset\": key,\n",
    "                                   \"cloud-aware\": \"no\",\n",
    "                                   \"format\": k,\n",
    "                                   \"file\": link,\n",
    "                                   \"time\": elapsed,\n",
    "                                   \"mean\": data_mean})\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(h5coro_beanchmarks)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['tool','dataset'], columns=['format'], values='time', aggfunc='mean')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('h5coro cloud optimized HDF5 performance')\n",
    "plt.xlabel('Tool')\n",
    "plt.ylabel('Mean Time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Format')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ba64d-d89c-4879-b965-f00d70956360",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Xarray + kerchunk, out of the box performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56958f-8c1d-4fd7-b885-6efb81af8da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is going to keep our numbers without modifying the i/o paramters\n",
    "regular_xarray_benchmarks = []\n",
    "kerchunk_benchmarks = []\n",
    "\n",
    "for key, dataset in test_dict.items():\n",
    "    for k, link in dataset[\"links\"].items():\n",
    "        print (f\"Processing: {link}\")\n",
    "        try:\n",
    "            log_filename = f\"logs/fsspec-xarray-{key}-{k}-default.log\"\n",
    "            \n",
    "            # Create a new FileHandler for each iteration\n",
    "            file_handler = logging.FileHandler(log_filename)\n",
    "            file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "            # Add the handler to the root logger\n",
    "            logging.getLogger().addHandler(file_handler)\n",
    " \n",
    "            start = time.time()\n",
    "            if \"kerchunk\" in link:\n",
    "                data_mean = kerchunk_result(link, dataset[\"group\"], dataset[\"variable\"])\n",
    "                elapsed = time.time() - start\n",
    "                kerchunk_benchmarks.append(\n",
    "                    {\"tool\": \"kerchunk\",\n",
    "                     \"dataset\": key,\n",
    "                     \"cloud-aware\": \"no\",\n",
    "                     \"format\": k,\n",
    "                     \"file\": link,\n",
    "                     \"time\": elapsed,\n",
    "                     \"mean\": data_mean})                \n",
    "            else:\n",
    "                ds = xr.open_dataset(fs.open(link, mode='rb'), group=dataset[\"group\"], engine=\"h5netcdf\", decode_cf=False)\n",
    "                data_mean = ds[dataset[\"variable\"]].mean()    \n",
    "                elapsed = time.time() - start\n",
    "                regular_xarray_benchmarks.append(\n",
    "                    {\"tool\": \"xarray\",\n",
    "                     \"dataset\": key,\n",
    "                     \"cloud-aware\": \"no\",\n",
    "                     \"format\": k,\n",
    "                     \"file\": link,\n",
    "                     \"time\": elapsed,\n",
    "                     \"mean\": data_mean})    \n",
    "            \n",
    "            logging.getLogger().removeHandler(file_handler)\n",
    "            file_handler.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8e67d-026e-4c6b-aa7d-b19dc10f4afd",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d5972-c5b9-4f29-979a-cf46c9654a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(kerchunk_benchmarks + regular_xarray_benchmarks)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['tool','dataset'], columns=['format'], values='time', aggfunc='mean')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "plt.title(\"Out of the box I/O parameters\", fontsize=10)\n",
    "plt.suptitle('Cloud-optimized HDF5 performance (less is better)', fontsize=14)\n",
    "\n",
    "plt.xlabel('Tool')\n",
    "plt.ylabel('Mean Time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Format')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ac2b9-989c-4246-bb89-b54b711dd695",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## h5py out of the box performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c29558-de50-44af-87e9-074092fcd0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regular_h5py_benchmarks = []\n",
    "\n",
    "for key, dataset in test_dict.items():\n",
    "    for k, link in dataset[\"links\"].items():\n",
    "        try:\n",
    "            if \"kerchunk\" in link:\n",
    "                continue   \n",
    "            print (f\"Processing: {link}\")\n",
    "            log_filename = f\"logs/fsspec-h5py-{key}-{k}_default.log\"\n",
    "            \n",
    "            # Create a new FileHandler for each iteration\n",
    "            file_handler = logging.FileHandler(log_filename)\n",
    "            file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "            # Add the handler to the root logger\n",
    "            logging.getLogger().addHandler(file_handler)\n",
    "            # this is mostly IO so no perf_counter is needed\n",
    "            start = time.time()\n",
    "            with h5py.File(fs.open(link, mode=\"rb\")) as f:\n",
    "                path = f\"{dataset['group']}/{dataset['variable']}\"\n",
    "                data = f[path][:]\n",
    "                data_mean = data.mean()\n",
    "                elapsed = time.time() - start\n",
    "                regular_h5py_benchmarks.append(\n",
    "                    {\"tool\": \"h5py\",\n",
    "                     \"dataset\": key,\n",
    "                     \"cloud-aware\": \"no\",\n",
    "                     \"format\": k,\n",
    "                     \"file\": link,\n",
    "                     \"time\": elapsed,\n",
    "                     \"mean\": data_mean})\n",
    "\n",
    "                logging.getLogger().removeHandler(file_handler)      \n",
    "                file_handler.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4232e98-1159-45eb-ba11-0f0dbb905d83",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa6dca-f408-4298-beca-f2839d4c3b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(regular_h5py_benchmarks)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['tool','dataset'], columns=['format'], values='time', aggfunc='mean')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.suptitle('Cloud-optimized HDF5 performance (less is better)', fontsize=14)\n",
    "plt.title(\"Out of the box I/O parameters\", fontsize=10)\n",
    "\n",
    "plt.xlabel('Tool')\n",
    "plt.ylabel('Mean Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Format')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b2032-9ab4-46e1-b1f8-2e62b656a265",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Aggregated plot by tool and different file sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcc5de-aae3-46aa-9474-1c90b9ff20a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(regular_h5py_benchmarks + kerchunk_benchmarks + regular_xarray_benchmarks + h5coro_beanchmarks)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['tool','dataset'], columns=['format'], values='time', aggfunc='mean')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.suptitle('Cloud-optimized HDF5 performance (less is better)', fontsize=14)\n",
    "plt.title(\"Out of the box I/O parameters\", fontsize=10)\n",
    "plt.xlabel('Tool')\n",
    "plt.ylabel('Mean Time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Format')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea67b0b-5e7f-4d1f-bca9-1f3cae7fe309",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Now let's run the tests with \"informed\" parameters, this is a I/O that aligns to the cloud-optimized granules chunking strategy and consolidated metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151834b-0b57-4a3d-98b5-8cfaffa37dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimized_h5py_benchmarks = []\n",
    "optimized_xarray_benchmarks = []\n",
    "\n",
    "for key, dataset in test_dict.items():\n",
    "    for k, link in dataset[\"links\"].items():\n",
    "        print(f\"Processing: {link}\")\n",
    "        try:\n",
    "            log_filename = f\"logs/fsspec-xarray-{key}-{k}.log\"\n",
    "            \n",
    "            # Create a new FileHandler for each iteration\n",
    "            file_handler = logging.FileHandler(log_filename)\n",
    "            file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "            # Add the handler to the root logger\n",
    "            logging.getLogger().addHandler(file_handler)\n",
    "            \n",
    "            io_params = {\n",
    "                \"fsspec_params\": {},\n",
    "                \"h5py_params\": {}\n",
    "            }\n",
    "            \n",
    "            if \"repacked\" in link:   \n",
    "                io_params ={\n",
    "                    \"fsspec_params\": {\n",
    "                        \"cache_type\": \"blockcache\",\n",
    "                        \"block_size\": 8*1024*1024\n",
    "                    },\n",
    "                    \"h5py_params\" : {\n",
    "                        \"driver_kwds\": {\n",
    "                            \"page_buf_size\": 64*1024*1024,\n",
    "                            \"rdcc_nbytes\": 8*1024*1024\n",
    "                        }\n",
    "\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            if \"kerchunk\" in link:\n",
    "                continue\n",
    "               \n",
    "            start = time.time()\n",
    "            ds = xr.open_dataset(fs.open(link, mode='rb', **io_params[\"fsspec_params\"]), group=dataset[\"group\"], engine=\"h5netcdf\", decode_cf=False)\n",
    "            data_mean = ds[dataset[\"variable\"]].mean()\n",
    "            elapsed = time.time() - start\n",
    "            optimized_xarray_benchmarks.append(\n",
    "                {\"tool\": \"xarray\",\n",
    "                 \"dataset\": key,\n",
    "                 \"cloud-aware\": \"yes\",\n",
    "                 \"format\": k,\n",
    "                 \"file\": link,\n",
    "                 \"time\": elapsed,\n",
    "                 \"mean\": data_mean})\n",
    "            \n",
    "            logging.getLogger().removeHandler(file_handler)\n",
    "            file_handler.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "for key, dataset in test_dict.items():\n",
    "    for k, link in dataset[\"links\"].items():\n",
    "        try:\n",
    "            if \"kerchunk\" in link:\n",
    "                continue   \n",
    "            print (f\"Processing: {link}\")\n",
    "            log_filename = f\"logs/fsspec-h5py-{key}-{k}_default.log\"\n",
    "            \n",
    "            # Create a new FileHandler for each iteration\n",
    "            file_handler = logging.FileHandler(log_filename)\n",
    "            file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "            # Add the handler to the root logger\n",
    "            logging.getLogger().addHandler(file_handler)\n",
    "            # this is mostly IO so no perf_counter is needed\n",
    "            start = time.time()\n",
    "            io_params = {\n",
    "                \"fsspec_params\": {},\n",
    "                \"h5py_params\": {}\n",
    "            }\n",
    "            \n",
    "            if \"repacked\" in link:   \n",
    "                io_params ={\n",
    "                    \"fsspec_params\": {\n",
    "                        \"cache_type\": \"blockcache\",\n",
    "                        \"block_size\": 8*1024*1024\n",
    "                    },\n",
    "                    \"h5py_params\" : {\n",
    "                        \"page_buf_size\": 64*1024*1024,\n",
    "                        \"rdcc_nbytes\": 8*1024*1024\n",
    "                    }\n",
    "                }            \n",
    "            with h5py.File(fs.open(link, mode=\"rb\", **io_params[\"fsspec_params\"]), **io_params[\"h5py_params\"]) as f:\n",
    "                path = f\"{dataset['group']}/{dataset['variable']}\"\n",
    "                data = f[path][:]\n",
    "                data_mean = data.mean()\n",
    "                elapsed = time.time() - start\n",
    "                optimized_h5py_benchmarks.append(\n",
    "                    {\"tool\": \"h5py\",\n",
    "                     \"dataset\": key,\n",
    "                     \"cloud-aware\": \"yes\",\n",
    "                     \"format\": k,\n",
    "                     \"file\": link,\n",
    "                     \"time\": elapsed,\n",
    "                     \"mean\": data_mean})\n",
    "\n",
    "                logging.getLogger().removeHandler(file_handler)      \n",
    "                file_handler.close()\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04414c2e-0666-4701-8ecc-7842727ede22",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2535a-8d3a-4e65-b21c-8db6b48074c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(optimized_h5py_benchmarks+h5coro_beanchmarks+optimized_xarray_benchmarks+kerchunk_benchmarks)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['tool','dataset'], columns=['format'], values='time', aggfunc='mean')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "plt.suptitle('Cloud-optimized HDF5 performance (less is better)', fontsize=14)\n",
    "plt.title(\"Informed I/O parameters\", fontsize=10)\n",
    "plt.xlabel('Tool')\n",
    "plt.ylabel('Mean Time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Format')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0db03e-5653-4908-ada1-16d723666e18",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Ploting tool specific performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47444e8a-6d59-42c2-baff-a3c85c447eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(regular_xarray_benchmarks+optimized_xarray_benchmarks)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['dataset','cloud-aware'], columns=['format'], values='time', aggfunc='mean')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Xarray \"Cloud-Aware\" Access Pattern Performance (less is better)')\n",
    "plt.xlabel('Tool')\n",
    "plt.ylabel('Mean Time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Format')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395f794-0ea7-4c26-8f64-0d2f9659d841",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Make one comparison plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe17a07-22e3-4b99-a50a-d3183425d15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(regular_h5py_benchmarks + \n",
    "                            kerchunk_benchmarks + \n",
    "                            regular_xarray_benchmarks + \n",
    "                            h5coro_beanchmarks + \n",
    "                            optimized_h5py_benchmarks + \n",
    "                            optimized_xarray_benchmarks)\n",
    "df[\"size\"] = df.dataset.str.extract(r\"-(\\dGB)\")\n",
    "df[\"product\"] = df.dataset.str.extract(r\"(ATL\\d{2})\")\n",
    "df.to_csv(\"benchmarks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90486527-a1f2-4a92-bee6-1b2f934aa24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pivot_df = df.pivot_table(index=[\"tool\", \"size\"], columns=[\"format\", \"cloud-aware\"], values=\"time\", aggfunc=\"mean\")\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88badbc0-a277-4aee-9236-d74327032d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\", rc={'axes.facecolor': '0.9'})\n",
    "# sns.set_palette(\"bright\", 4)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,6), layout=\"constrained\")\n",
    "\n",
    "pivot_df.plot(kind=\"bar\", ax=ax, \n",
    "              color=[\"tab:cyan\", \"tab:blue\", \"tab:pink\", \"tab:red\"],\n",
    "              xlabel=\"\", fontsize=15);\n",
    "ax.legend(labels = [\"Optimized\", \"Optimized with informed io parameters\", \"Original\", \"Original with informed io parameters\"], fontsize=15)\n",
    "ax.set_ylabel(\"Time (s)\", fontsize=20)\n",
    "\n",
    "# Make two level axis\n",
    "def parse_text(s):\n",
    "    return re.sub(r\"[()]\", \"\", s).split(\", \")\n",
    "\n",
    "# Retrieve and parse axis labels and position\n",
    "tool, size, x, y = map(np.array, zip(*[(*parse_text(l.get_text()), *l.get_position()) for l in ax.get_xticklabels()]))\n",
    "# Make labels and x-positions for seconary axis\n",
    "sec_x, sec_label = zip(*[(x[tool == tool_name].mean(), \"\\n\"+tool_name) for tool_name in np.unique(tool)])\n",
    "# Assign ticks and labels\n",
    "ax.set_xticks(x, size, rotation=0);\n",
    "sec = ax.secondary_xaxis(location=0);\n",
    "sec.set_xticks(sec_x, sec_label, fontsize=18);\n",
    "sec.tick_params(length=0)\n",
    "\n",
    "sepa_x = np.array([x[tool == tool_name].min()-0.5 for tool_name in np.unique(tool)] + [x.max()+0.5])\n",
    "[ax.axvline(xs, c='k', ymin=-.1, clip_on=False, zorder=3) for xs in sepa_x];\n",
    "\n",
    "# Use plot_benchmark_results.ipynb to generate saveable png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd30a5-952e-428f-b908-9897fac81aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae595359-3e8a-4072-89b4-bd2e52d9ec12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
